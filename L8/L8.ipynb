{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  8A - L1 Introduction to Recognition\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does Recognition Involve\n",
    "\n",
    "**Verification**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L81.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(a) Verification: is that a lamp?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Detection**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L82.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(b) Detection: are there people?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Identification**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L83.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(c) Identification: is that Potala Palace?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Object Categorization**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L84.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(d) Object Categorization</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Scene and context Categorization**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L85.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(e) Scene and context Categorization</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Categorization\n",
    "\n",
    "### Instance-level recognition problem\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L86.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(a) Johns' car</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Generic categorization problem\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L87.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(b) Those are cars</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Object Categorization\n",
    "\n",
    "Task: *Given a (small) number of training images of a category, recognize a-priori unknown instances of that category and assign the correct category label*\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L88.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(c) We have to agree on a set of labels. <strong>Which catogires are the best for visual identification?</strong> </figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Object Categories\n",
    "\n",
    "*Basic Level Categories in human categorization [Rosch 76, Lakoff 87]*\n",
    "\n",
    "- The highest level at which category members have similar perceived shape\n",
    "- The highest level at which a single mental image reflects the entire category\n",
    "- The level at which human subjects are usually fastest at identifying category members\n",
    "- The first level named and understood by children\n",
    "- The highest level at which a person uses similar motor actions for interaction with category members\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L89.png\" width=300/>\n",
    "  <center><figcaption>Fig 3 Aaron PhD</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of Categories\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L810.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(a) <strong>How many object categories are there? [Biederman 1987]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L811.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(b) <strong>Functional Categories e.g. chairs = \"something you can sit on\" [K. Grauman, B. Leibe]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L812.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(c) <strong>Ad-hoc categories e.g. \"something you can find in an office environment\" [K. Grauman, B. Leibe]</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Recognition\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L813.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(a) <strong>Autonomous agents able to detect objects</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L814.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(b) <strong>Labeling people. <br/><font color=\"red\">I swear I didn't cheat, this the image in the lecture</font></strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L815.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(c) <strong>Posing visual queries [Belhumeur et al.]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L816.png\" width=300/>\n",
    "    <center><figcaption><strong>Fig 5(d) Finding visually similar objects</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L817.png\" width=300/>\n",
    "  <img src=\"imgs/L818.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(a) <strong>Robustness</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L819.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(b) <strong>Robustness: Realistic scenes are crowded, cluttered, have overlapping objects</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L820.png\" width=300/>\n",
    "  <img src=\"imgs/L821.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(c) <strong>Importance of conext [Fei-Fei, Fergus & Torralba]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Complexity**\n",
    "- Thousands to millions of pixels in an image\n",
    "- 3,000-30,000 human recognizable object categories\n",
    "- 30+ degrees of feedom in the pose of articulated objects (humans)\n",
    "- Billions of images indexed by Google Image Search\n",
    "- In 2011, 6 billion photos uploaded *per month*\n",
    "- Approximately one billion camera phones sold in 2013\n",
    "- About half of the cerebral cortex in primates is devoted to processing visual information [Felleman and van Essen 1991]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Works?\n",
    "\n",
    "### What worked most reliably \"yesterday\"\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L822.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(a) <strong>Reading license plates (real easy), zip codes, checks [Lana Lazebnik]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L823.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(b) <strong>Fingerprint recognition</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L824.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(c) <strong>Face detection (Today recognition)</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L825.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(d) <strong>Recognition of flat textured objects (CD covers, book covers, etc.) [Lana Lazebnik]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L826.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(d) <strong>GoogleNet 2014</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L827.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(e) <strong>Just in: GoogleNet-no context needed?</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going forward\n",
    "\n",
    "- These days much of strong label \"recognition\" is really machine learning applied to patterns of pixel intensities.\n",
    "    - To cover this would require deep understanding of machine learning. Another class - or six...\n",
    " - We'll focus on some general principals of generative vs discriminative methods and the representations of the image that they use\n",
    "- And then we'll spend some time on *activity recognition* from video "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
