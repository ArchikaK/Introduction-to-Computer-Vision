{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  8A - L1 Introduction to Recognition\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does Recognition Involve\n",
    "\n",
    "**Verification**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L81.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(a) Verification: is that a lamp?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Detection**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L82.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(b) Detection: are there people?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Identification**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L83.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(c) Identification: is that Potala Palace?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Object Categorization**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L84.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(d) Object Categorization</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Scene and context Categorization**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L85.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(e) Scene and context Categorization</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Categorization\n",
    "\n",
    "### Instance-level recognition problem\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L86.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(a) Johns' car</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Generic categorization problem\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L87.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(b) Those are cars</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Object Categorization\n",
    "\n",
    "Task: *Given a (small) number of training images of a category, recognize a-priori unknown instances of that category and assign the correct category label*\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L88.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(c) We have to agree on a set of labels. <strong>Which catogires are the best for visual identification?</strong> </figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Object Categories\n",
    "\n",
    "*Basic Level Categories in human categorization [Rosch 76, Lakoff 87]*\n",
    "\n",
    "- The highest level at which category members have similar perceived shape\n",
    "- The highest level at which a single mental image reflects the entire category\n",
    "- The level at which human subjects are usually fastest at identifying category members\n",
    "- The first level named and understood by children\n",
    "- The highest level at which a person uses similar motor actions for interaction with category members\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L89.png\" width=300/>\n",
    "  <center><figcaption>Fig 3 Aaron PhD</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of Categories\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L810.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(a) <strong>How many object categories are there? [Biederman 1987]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L811.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(b) <strong>Functional Categories e.g. chairs = \"something you can sit on\" [K. Grauman, B. Leibe]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L812.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(c) <strong>Ad-hoc categories e.g. \"something you can find in an office environment\" [K. Grauman, B. Leibe]</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Recognition\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L813.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(a) <strong>Autonomous agents able to detect objects</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L814.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(b) <strong>Labeling people. <br/><font color=\"red\">I swear I didn't cheat, this the image in the lecture</font></strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L815.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(c) <strong>Posing visual queries [Belhumeur et al.]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L816.png\" width=300/>\n",
    "    <center><figcaption><strong>Fig 5(d) Finding visually similar objects</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L817.png\" width=300/>\n",
    "  <img src=\"imgs/L818.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(a) <strong>Robustness</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L819.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(b) <strong>Robustness: Realistic scenes are crowded, cluttered, have overlapping objects</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L820.png\" width=300/>\n",
    "  <img src=\"imgs/L821.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(c) <strong>Importance of conext [Fei-Fei, Fergus & Torralba]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Complexity**\n",
    "- Thousands to millions of pixels in an image\n",
    "- 3,000-30,000 human recognizable object categories\n",
    "- 30+ degrees of feedom in the pose of articulated objects (humans)\n",
    "- Billions of images indexed by Google Image Search\n",
    "- In 2011, 6 billion photos uploaded *per month*\n",
    "- Approximately one billion camera phones sold in 2013\n",
    "- About half of the cerebral cortex in primates is devoted to processing visual information [Felleman and van Essen 1991]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Works?\n",
    "\n",
    "### What worked most reliably \"yesterday\"\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L822.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(a) <strong>Reading license plates (real easy), zip codes, checks [Lana Lazebnik]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L823.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(b) <strong>Fingerprint recognition</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L824.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(c) <strong>Face detection (Today recognition)</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L825.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(d) <strong>Recognition of flat textured objects (CD covers, book covers, etc.) [Lana Lazebnik]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L826.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(d) <strong>GoogleNet 2014</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L827.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(e) <strong>Just in: GoogleNet-no context needed?</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going forward\n",
    "\n",
    "- These days much of strong label \"recognition\" is really machine learning applied to patterns of pixel intensities.\n",
    "    - To cover this would require deep understanding of machine learning. Another class - or six...\n",
    " - We'll focus on some general principals of generative vs discriminative methods and the representations of the image that they use\n",
    "- And then we'll spend some time on *activity recognition* from video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  8B - L1 Classification: Generative Models\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification\n",
    "\n",
    "Given a collection of labeled examples, come up with a function that will predict the labels of new examples.\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L828.png\" width=300/>\n",
    "    <center><figcaption>Fig 7</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "How good is the function we come up with to do the classification? (What does \"good\" mean?)\n",
    "\n",
    "Depends on:\n",
    "\n",
    "- What mistakes does it make\n",
    "- Cost associated with the mistakes\n",
    "\n",
    "Since we know the desired labels of training data, we want to *minimize the expected misclassification*\n",
    "\n",
    "Two general strategies\n",
    "\n",
    "- Use the training data to build representative probability model; separately model class-conditional densities and priors (**Generative**)\n",
    "\n",
    "- Directly construct a good decision boundary, model the posterior (**Discriminative**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative\n",
    "\n",
    "Given Labeled training examples, predict labels for new examples\n",
    "\n",
    "- Notation: ($4\\rightarrow 9$) - object is a '4' but you call it a '9'\n",
    "- We'll assume the cost of ($X\\rightarrow X$) is zero\n",
    "\n",
    "Consider the two-class (binary) decision problem:\n",
    "\n",
    "- L($4\\rightarrow 9$): Loss of classifying a 4 as a 9\n",
    "- L($9\\rightarrow 4$): Loss of classifying a 9 as a 4\n",
    "\n",
    "***Risk*** of a classifier startegy $S$ is expected loss:\n",
    "\n",
    "<font color=\"blue\">$$R(S) = Pr(4\\rightarrow 9|\\text{using S}) L(4\\rightarrow 9) + Pr(9\\rightarrow 4|\\text{using S}) L(9\\rightarrow 4)$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Risk\n",
    "\n",
    "### Supervised classification: minimal risk\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L829.png\" width=300/>\n",
    "    <center><figcaption>Fig 8(a) <strong>At best decision boundary, either choise of label yields same expected loss.</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "If we choose class \"four\" at boundary, expected loss is:\n",
    "\n",
    "<font color=\"blue\">$$ = P(\\text{class is }9|x)L(9\\rightarrow 4) + P(\\text{class is }4|x)L(4\\rightarrow 4)$$\n",
    "$$ = P(\\text{class is }9|x)L(9\\rightarrow 4)$$</font>\n",
    "\n",
    "If we choose class \"nine\" at boundary, expected loss is:\n",
    "<font color=\"blue\">$$ = P(\\text{class is }4|x)L(4\\rightarrow 9)$$</font>\n",
    "\n",
    "So, best decision boundary is at point $x$ where:\n",
    "\n",
    "<font color=\"blue\">$$P(\\text{class is }9|x)L(9\\rightarrow 4) = P(\\text{class is }4|x)L(4\\rightarrow 9)$$</font>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L830.png\" width=300/>\n",
    "    <center><figcaption>Fig 8(b)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**How to evaluate <font color=\"blue\">$P(\\text{class is }9|x)$</font> and <font color=\"blue\">$P(\\text{class is }4|x)$</font>**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Learning Skin Colors\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L831.png\" width=600/>\n",
    "  <img src=\"imgs/L832.png\" width=600/>\n",
    "    <center><figcaption>Fig 9</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<font color=\"blue\">$$P(skin|x) = \\frac{P(x|skin)P(skin)}{P(x)}$$</font>\n",
    "\n",
    "$P(skin|x)$: posterior\n",
    "\n",
    "$P(x)$: prior\n",
    "\n",
    "$P(x|skin)$: likelihood (we have this from the data)\n",
    "\n",
    "<font color=\"blue\">$$P(skin|x) \\propto P(x|skin)P(skin)$$</font>\n",
    "\n",
    "**Where does the prior come from?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Is this skin or not?\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L833.png\" width=600/>\n",
    "    <center><figcaption>Fig 10</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes rule in (ab)use\n",
    "\n",
    "Likelihood ration test (assuming cost of errors is the same):\n",
    "\n",
    "If <font color=\"blue\">$P(x|skin)P(skin) > P(x|\\sim skin)P(\\sim skin)$</font> classify $x$ as skin <font color=\"green\">(Bayes rule)</font>\n",
    "\n",
    "(if the costs are different just re-weight)\n",
    "\n",
    "...but I don't really know prior <font color=\"blue\">$P(skin)$</font>...\n",
    "\n",
    "...but I can assume it it some constant <font color=\"blue\">$\\Omega$</font>...\n",
    "\n",
    "... so with some training data I can *estimate* <font color=\"blue\">$\\Omega$</font>...\n",
    "\n",
    "... and with the same training data I can *measure* the *likelihood densities* of *both* <font color=\"blue\">$P(x|skin)$</font> and <font color=\"blue\">$P(x|\\sim skin)$</font>...\n",
    "\n",
    "So... I can more or less come up with a rule...\n",
    "\n",
    "Now for every pixel in a new image, we can estimate probability that it is generated by skin:\n",
    "\n",
    "If <font color=\"blue\">$P(skin|x) > \\theta$</font> classify as skin; otherwise not\n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L834.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(a):<strong> Brighter pixels are higher probability of being skin</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L835.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(b):<strong> A video image and its flesh probability image</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L836.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(c)</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More General Generative Models\n",
    "\n",
    "For a given measurement $x$ and set of classes $c_i$ choose $c*$ by:\n",
    "\n",
    "<font color=\"blue\">$$c* = argmax_c P(c|x) = argmax_c P(c)P(x|c)$$</font>\n",
    "\n",
    "### Continuous generative models\n",
    "\n",
    "- If $x$ is continuous, need *likelihood* density model of *$p(x|c)$*\n",
    "- Typically parametric - Gaussian or mixture of Gaussians\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L837.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(a)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "- Why not just some histogram or some KNN (Parzen window) method?\n",
    "    - You might...\n",
    "    - But you would need lots and lots of data everywhere you might get a point\n",
    "    - The whole point of modeling with a parameterized model is not to need lots of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generative Models\n",
    "\n",
    "- Firm probabilistic grounding\n",
    "- Allows inclusing of prior knowledge\n",
    "- Parametric modeling of likelihood permits using small number of examples\n",
    "- New classes do not perturb previous models\n",
    "- Others: \n",
    "    - Can take advantage of unlabelled data\n",
    "    - Can be used to generate samples\n",
    "    \n",
    "\n",
    "- And just where did you get those priors?\n",
    "- Why are you modeling those obviously "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
