{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  8A - L1 Introduction to Recognition\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does Recognition Involve\n",
    "\n",
    "**Verification**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L81.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(a) Verification: is that a lamp?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Detection**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L82.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(b) Detection: are there people?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Identification**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L83.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(c) Identification: is that Potala Palace?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Object Categorization**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L84.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(d) Object Categorization</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Scene and context Categorization**\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L85.png\" width=300/>\n",
    "  <center><figcaption>Fig 1(e) Scene and context Categorization</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Categorization\n",
    "\n",
    "### Instance-level recognition problem\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L86.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(a) Johns' car</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Generic categorization problem\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L87.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(b) Those are cars</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Object Categorization\n",
    "\n",
    "Task: *Given a (small) number of training images of a category, recognize a-priori unknown instances of that category and assign the correct category label*\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L88.png\" width=300/>\n",
    "  <center><figcaption>Fig 2(c) We have to agree on a set of labels. <strong>Which catogires are the best for visual identification?</strong> </figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Object Categories\n",
    "\n",
    "*Basic Level Categories in human categorization [Rosch 76, Lakoff 87]*\n",
    "\n",
    "- The highest level at which category members have similar perceived shape\n",
    "- The highest level at which a single mental image reflects the entire category\n",
    "- The level at which human subjects are usually fastest at identifying category members\n",
    "- The first level named and understood by children\n",
    "- The highest level at which a person uses similar motor actions for interaction with category members\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L89.png\" width=300/>\n",
    "  <center><figcaption>Fig 3 Aaron PhD</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of Categories\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L810.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(a) <strong>How many object categories are there? [Biederman 1987]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L811.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(b) <strong>Functional Categories e.g. chairs = \"something you can sit on\" [K. Grauman, B. Leibe]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L812.png\" width=300/>\n",
    "    <center><figcaption>Fig 4(c) <strong>Ad-hoc categories e.g. \"something you can find in an office environment\" [K. Grauman, B. Leibe]</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Recognition\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L813.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(a) <strong>Autonomous agents able to detect objects</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L814.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(b) <strong>Labeling people. <br/><font color=\"red\">I swear I didn't cheat, this the image in the lecture</font></strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L815.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(c) <strong>Posing visual queries [Belhumeur et al.]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L816.png\" width=300/>\n",
    "    <center><figcaption><strong>Fig 5(d) Finding visually similar objects</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L817.png\" width=300/>\n",
    "  <img src=\"imgs/L818.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(a) <strong>Robustness</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L819.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(b) <strong>Robustness: Realistic scenes are crowded, cluttered, have overlapping objects</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L820.png\" width=300/>\n",
    "  <img src=\"imgs/L821.png\" width=300/>\n",
    "    <center><figcaption>Fig 5(c) <strong>Importance of conext [Fei-Fei, Fergus & Torralba]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Complexity**\n",
    "- Thousands to millions of pixels in an image\n",
    "- 3,000-30,000 human recognizable object categories\n",
    "- 30+ degrees of feedom in the pose of articulated objects (humans)\n",
    "- Billions of images indexed by Google Image Search\n",
    "- In 2011, 6 billion photos uploaded *per month*\n",
    "- Approximately one billion camera phones sold in 2013\n",
    "- About half of the cerebral cortex in primates is devoted to processing visual information [Felleman and van Essen 1991]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Works?\n",
    "\n",
    "### What worked most reliably \"yesterday\"\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L822.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(a) <strong>Reading license plates (real easy), zip codes, checks [Lana Lazebnik]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L823.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(b) <strong>Fingerprint recognition</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L824.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(c) <strong>Face detection (Today recognition)</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L825.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(d) <strong>Recognition of flat textured objects (CD covers, book covers, etc.) [Lana Lazebnik]</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L826.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(d) <strong>GoogleNet 2014</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L827.png\" width=300/>\n",
    "    <center><figcaption>Fig 6(e) <strong>Just in: GoogleNet-no context needed?</strong></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going forward\n",
    "\n",
    "- These days much of strong label \"recognition\" is really machine learning applied to patterns of pixel intensities.\n",
    "    - To cover this would require deep understanding of machine learning. Another class - or six...\n",
    " - We'll focus on some general principals of generative vs discriminative methods and the representations of the image that they use\n",
    "- And then we'll spend some time on *activity recognition* from video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  8B - L1 Classification: Generative Models\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification\n",
    "\n",
    "Given a collection of labeled examples, come up with a function that will predict the labels of new examples.\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L828.png\" width=300/>\n",
    "    <center><figcaption>Fig 7</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "How good is the function we come up with to do the classification? (What does \"good\" mean?)\n",
    "\n",
    "Depends on:\n",
    "\n",
    "- What mistakes does it make\n",
    "- Cost associated with the mistakes\n",
    "\n",
    "Since we know the desired labels of training data, we want to *minimize the expected misclassification*\n",
    "\n",
    "Two general strategies\n",
    "\n",
    "- Use the training data to build representative probability model; separately model class-conditional densities and priors (**Generative**)\n",
    "\n",
    "- Directly construct a good decision boundary, model the posterior (**Discriminative**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative\n",
    "\n",
    "Given Labeled training examples, predict labels for new examples\n",
    "\n",
    "- Notation: ($4\\rightarrow 9$) - object is a '4' but you call it a '9'\n",
    "- We'll assume the cost of ($X\\rightarrow X$) is zero\n",
    "\n",
    "Consider the two-class (binary) decision problem:\n",
    "\n",
    "- L($4\\rightarrow 9$): Loss of classifying a 4 as a 9\n",
    "- L($9\\rightarrow 4$): Loss of classifying a 9 as a 4\n",
    "\n",
    "***Risk*** of a classifier startegy $S$ is expected loss:\n",
    "\n",
    "<font color=\"blue\">$$R(S) = Pr(4\\rightarrow 9|\\text{using S}) L(4\\rightarrow 9) + Pr(9\\rightarrow 4|\\text{using S}) L(9\\rightarrow 4)$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Risk\n",
    "\n",
    "### Supervised classification: minimal risk\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L829.png\" width=300/>\n",
    "    <center><figcaption>Fig 8(a) <strong>At best decision boundary, either choise of label yields same expected loss.</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "If we choose class \"four\" at boundary, expected loss is:\n",
    "\n",
    "<font color=\"blue\">$$ = P(\\text{class is }9|x)L(9\\rightarrow 4) + P(\\text{class is }4|x)L(4\\rightarrow 4)$$\n",
    "$$ = P(\\text{class is }9|x)L(9\\rightarrow 4)$$</font>\n",
    "\n",
    "If we choose class \"nine\" at boundary, expected loss is:\n",
    "<font color=\"blue\">$$ = P(\\text{class is }4|x)L(4\\rightarrow 9)$$</font>\n",
    "\n",
    "So, best decision boundary is at point $x$ where:\n",
    "\n",
    "<font color=\"blue\">$$P(\\text{class is }9|x)L(9\\rightarrow 4) = P(\\text{class is }4|x)L(4\\rightarrow 9)$$</font>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L830.png\" width=300/>\n",
    "    <center><figcaption>Fig 8(b)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**How to evaluate <font color=\"blue\">$P(\\text{class is }9|x)$</font> and <font color=\"blue\">$P(\\text{class is }4|x)$</font>**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Learning Skin Colors\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L831.png\" width=600/>\n",
    "  <img src=\"imgs/L832.png\" width=600/>\n",
    "    <center><figcaption>Fig 9</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<font color=\"blue\">$$P(skin|x) = \\frac{P(x|skin)P(skin)}{P(x)}$$</font>\n",
    "\n",
    "$P(skin|x)$: posterior\n",
    "\n",
    "$P(x)$: prior\n",
    "\n",
    "$P(x|skin)$: likelihood (we have this from the data)\n",
    "\n",
    "<font color=\"blue\">$$P(skin|x) \\propto P(x|skin)P(skin)$$</font>\n",
    "\n",
    "**Where does the prior come from?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin detection using OpenCV\n",
    "https://www.pyimagesearch.com/2014/08/18/skin-detection-step-step-example-using-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Run the following code in the terminal so you can exit gracefully. \n",
    "# Source: https://www.pyimagesearch.com/2014/08/18/skin-detection-step-step-example-using-python-opencv/\n",
    "# \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    " \n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    " \n",
    "# define the upper and lower boundaries of the HSV pixel\n",
    "# intensities to be considered 'skin'\n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# keep looping over the frames in the video\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    " \n",
    "    # resize the frame, convert it to the HSV color space,\n",
    "    # and determine the HSV pixel intensities that fall into\n",
    "    # the speicifed upper and lower boundaries\n",
    "    frame = resize(frame, width = 400)\n",
    "    converted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    skinMask = cv2.inRange(converted, lower, upper)\n",
    " \n",
    "    # apply a series of erosions and dilations to the mask\n",
    "    # using an elliptical kernel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    " \n",
    "    # blur the mask to help remove noise, then apply the\n",
    "    # mask to the frame\n",
    "    skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
    "    skin = cv2.bitwise_and(frame, frame, mask = skinMask)\n",
    " \n",
    "    # show the skin in the image along with the mask\n",
    "    cv2.imshow(\"images\", np.hstack([frame, skin]))\n",
    " \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L838.png\" width=600/>\n",
    "    <center><figcaption>The black mask on my chin is probably due to my black beard</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Is this skin or not?\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L833.png\" width=600/>\n",
    "    <center><figcaption>Fig 10</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes rule in (ab)use\n",
    "\n",
    "Likelihood ration test (assuming cost of errors is the same):\n",
    "\n",
    "If <font color=\"blue\">$P(x|skin)P(skin) > P(x|\\sim skin)P(\\sim skin)$</font> classify $x$ as skin <font color=\"green\">(Bayes rule)</font>\n",
    "\n",
    "(if the costs are different just re-weight)\n",
    "\n",
    "...but I don't really know prior <font color=\"blue\">$P(skin)$</font>...\n",
    "\n",
    "...but I can assume it it some constant <font color=\"blue\">$\\Omega$</font>...\n",
    "\n",
    "... so with some training data I can *estimate* <font color=\"blue\">$\\Omega$</font>...\n",
    "\n",
    "... and with the same training data I can *measure* the *likelihood densities* of *both* <font color=\"blue\">$P(x|skin)$</font> and <font color=\"blue\">$P(x|\\sim skin)$</font>...\n",
    "\n",
    "So... I can more or less come up with a rule...\n",
    "\n",
    "Now for every pixel in a new image, we can estimate probability that it is generated by skin:\n",
    "\n",
    "If <font color=\"blue\">$P(skin|x) > \\theta$</font> classify as skin; otherwise not\n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L834.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(a):<strong> Brighter pixels are higher probability of being skin</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L835.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(b):<strong> A video image and its flesh probability image</strong></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L836.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(c)</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n",
      "Accuracy: 76.377953\n"
     ]
    }
   ],
   "source": [
    "# Example of Naive Bayes implemented from Scratch in Python\n",
    "## Source: https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\"\"\"\n",
    "The test problem we will use in this tutorial is the Pima Indians Diabetes problem.\n",
    "This problem is comprised of 768 observations of medical details for Pima indians patents. The records describe instantaneous measurements taken from the patient such as their age, the number of times pregnant and blood workup. All patients are women aged 21 or older. All attributes are numeric, and their units vary from attribute to attribute.\n",
    "Each record has a class value that indicates whether the patient suffered an onset of diabetes within 5 years of when the measurements were taken (1) or not (0).\n",
    "This is a standard dataset that has been studied a lot in machine learning literature. A good prediction accuracy is 70%-76%.\n",
    "Below is a sample from the pima-indians.data.csv file to get a sense of the data we will be working with (update: download from here).\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = [l for l in lines]\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "            \n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    filename = 'nvb_data.csv'\n",
    "    splitRatio = 0.67\n",
    "    dataset = loadCsv(filename)\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    print('Split %d rows into train=%d and test=%d rows' % (len(dataset), len(trainingSet), len(testSet)))\n",
    "    # prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    # test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For example on Naive Bayes on images** https://github.com/Chinmoy007/Skin-detection\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L839.png\" width=700/>\n",
    "  <img src=\"imgs/L840.png\" width=700/>\n",
    "  <center><figcaption>Output using this code. Not very imptressive</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More General Generative Models\n",
    "\n",
    "For a given measurement $x$ and set of classes $c_i$ choose $c*$ by:\n",
    "\n",
    "<font color=\"blue\">$$c* = argmax_c P(c|x) = argmax_c P(c)P(x|c)$$</font>\n",
    "\n",
    "### Continuous generative models\n",
    "\n",
    "- If $x$ is continuous, need *likelihood* density model of *$p(x|c)$*\n",
    "- Typically parametric - Gaussian or mixture of Gaussians\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L837.png\" width=400/>\n",
    "    <center><figcaption>Fig 11(a)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "- Why not just some histogram or some KNN (Parzen window) method?\n",
    "    - You might...\n",
    "    - But you would need lots and lots of data everywhere you might get a point\n",
    "    - The whole point of modeling with a parameterized model is not to need lots of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generative Models\n",
    "\n",
    "- Firm probabilistic grounding\n",
    "- Allows inclusing of prior knowledge\n",
    "- Parametric modeling of likelihood permits using small number of examples\n",
    "- New classes do not perturb previous models\n",
    "- Others: \n",
    "    - Can take advantage of unlabelled data\n",
    "    - Can be used to generate samples\n",
    "    \n",
    "**Downsides**\n",
    "- And just where did you get those priors?\n",
    "- Why are you modeling those obviously non-C points?\n",
    "- The example hard cases aren't special\n",
    "- If you have lots of data, doesn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
