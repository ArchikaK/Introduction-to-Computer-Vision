{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  3A - L1 Camera and Images\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an image?\n",
    "\n",
    "- In previous lesson: a function- a 2D pattern of intensity values\n",
    "- Here: 1 2D projection of 3D points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First known Photograph - Heliograph\n",
    "\n",
    "The first photograph was taken by Joseph Nicephore Niepce in 1826. The below image is a reproduction made in 1952\n",
    "\n",
    "<figure>\n",
    "  <img src=\"first_photo.jpg\" /> \n",
    "    <center><figcaption>Fig.1 The reproduction of the first photograph <a href=\"https://en.wikipedia.org/wiki/History_of_photography\">Source</a></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imaging System\n",
    "\n",
    "### What is a camera?\n",
    "It's some device that allows the <u>**projection**</u> of light from three dimensions, to some medium (film, sensor,..etc) that will record the light pattern.\n",
    "\n",
    "<br />\n",
    "\n",
    "When you project a scene to the camera, you lose 3D information, and you have to find out what went out in the lost dimesnion. For instance, the image below were taken by a camera from front and right side. The projection from the right side shows the realistic depection of the globe painted on the side walk. \n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"projection_ex.png\" />\n",
    "  <center><figcaption>Fig.2(a) Example of projection. Notice the strange guy at the top of the globe</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"projection_ex2.png\" />\n",
    "  <center><figcaption>Fig.2(b) The real view of the projection as appears from right side</figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Formation\n",
    "\n",
    "As shown in figure 3(a), a light is reflected from a point to a film will create an image. However, a single point will reflect lights all over the film. In order to solve this problem, we place a barrier, with a small holes **(aperture)** in it that each will allow single light through it to the film as in figure 3(b)\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"image_formation_1.png\" />\n",
    "  <center><figcaption>Fig.3(a) Light comes from a point poroject all over the film  </figcaption></center>\n",
    "</figure>\n",
    "<figure>\n",
    "  <img src=\"image_formation_2.png\" />\n",
    "  <center><figcaption>Fig.3(b) A barrier with small holls (aperture) is placed between the scene and the film to allow only single light angle to the film   </figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture\n",
    "\n",
    "<font color=\"blue\">How does aperture affect the image that we see? How does the size affect the image?</font>\n",
    "\n",
    "The bluriness of the image is directly related to the size of the arpeture. As the arpeture size decreases, the bluriness decrease and the crisper images are produced. Aperture sizes are in mm (e.g. 2mm, 1mm, 0.6mm, and 0.35mm)\n",
    "\n",
    "<font color=\"blue\">Why not making the size very very small?</font>\n",
    "\n",
    "Because of diffraction effect due to the wave nature of light.\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"starburst_night.jpg\" />\n",
    "    <center><figcaption>Fig.4 effect of aperture size on the image <a href=\"https://www.slrlounge.com/diffraction-aperture-and-starburst-effects/\">source</a> </figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenses\n",
    "\n",
    "We don't really use pinhole cameras anymore. Instead, we use lenses. Lenses are desinged to project all lights comming from a point at a particular distance away to the same point on the film. However, as in Figure 5, the challange is that lights comming from different distance will be projected at slightly different points on the film (circle of confusion)\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"lenses_1.png\" />\n",
    "  <center><figcaption>Fig.5(a): Shows lenses' concept and the circle of confusion </figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<font color=\"blue\">Lenses Components</font>\n",
    "- Optical axis: light passes straight through unbent\n",
    "- Paralell lights are all bent to the same point\n",
    "- Focal point: a point where parallel lights are bent to\n",
    "- Aperture: to reduce the amount of spread of things, by restricting the set of rays that are coming in.\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"lenses_2.png\" />\n",
    "  <center><figcaption>Fig.5(b): Shows lenses' components</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thin Lenses\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<figure>\n",
    "  <img src=\"thin_lenses.png\" />\n",
    "  <center><figcaption>Fig.6(a) depicts thin lenses</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "  <img src=\"thin_lenses_2.png\" />\n",
    "  <center><figcaption>Fig.6(b) film lens diagram</figcaption></center>\n",
    "</figure>\n",
    "<figure>\n",
    "  <img src=\"thin_lenses_3.png\" />\n",
    "  <center><figcaption>Fig.6(c) film lens diagram</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<font color=\"blue\">Can we predict the relationship between, say $d_0$ and $d_i$ given lens with a given focal point where $d_0$ is the distance of the object, and $d_i$ is the distance from the lens to the image (Figure 6(a))?</font><br />\n",
    "\n",
    "Using similar triangles in Figure 6(b), we can reason that given the point $P$ at $y$ and projected at point $P'$ at $-y$ \n",
    "\n",
    "$$\\frac{-y'}{y} = \\frac{||z'||}{||z||}$$\n",
    "\n",
    "Also, using similar triangles in Figure 6(c), we can reason that\n",
    "\n",
    "$$\\frac{-y'}{y} = \\frac{||z'|| - f}{f}$$\n",
    "\n",
    "\n",
    "$$\\implies \\frac{1}{||z||} = \\frac{1}{f} - \\frac{1}{||z'||}$$\n",
    "\n",
    "$$\\implies \\frac{1}{f} =  \\frac{1}{||z||} + \\frac{1}{||z'||}$$ \n",
    "<br/>\n",
    "<center>(Thin Lense Equation)</center>\n",
    "\n",
    "\n",
    "$y$: height of a point from the optical axis <br/>\n",
    "$y'$: height of the projection of $P$ from the optical axis <br/>\n",
    "$z$: distance to the world <br/>\n",
    "$z'$: distance from lense to the image plane <br/>\n",
    "\n",
    "<font color=\"green\">So, any point that satisfy the thin lense Equation will be in focus. Hence, by moving the lense back and forward, we change where in the world things are in focus</font> <br />\n",
    "\n",
    "\n",
    "Check out: http://www.phy.ntnu.edu.tw/ntnujava/index.php?topic=48\n",
    "\n",
    "<br />\n",
    "\n",
    "<font color=\"blue\">**Quize**</font>\n",
    "\n",
    "<figure>\n",
    "  <img src=\"thin_lenses_quiz.png\" />\n",
    "  <center><figcaption>Fig.6(d): Thin lense quiz</figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Z1 == 1000.000000, Z' == 52.631579\n",
      "When Z1 == 2000.000000, Z' == 51.282051\n"
     ]
    }
   ],
   "source": [
    "f = 50.0\n",
    "z = [1000.0,2000.0] # in mm\n",
    "for zi in z:\n",
    "    zp = 1/(1/f - 1/zi)\n",
    "    print(\"When Z1 == %f, Z' == %f\" % (zi,zp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Focus\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"varying_focus.gif\" />\n",
    "    <center><figcaption>Fig.7: The effect of varying focus <a href=\"https://www269.lunapic.com/editor/?action=focus-anim\"> Source</a></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth of field\n",
    "\n",
    "It is concerned with how much of focus change occurs for a certain point as the lense move in and out. The DoF is controlled by the aperture. With wide aperture, the rays diverge quite a bit, and hence moving the plane in a little bit cause the rays to spread out alot. On the other hand, with smaller aperture, the spread is much less as the plane is moving in (Figure 8a,b). \n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"dof.png\" />\n",
    "    <center><figcaption>Fig.8 (a): depth of field <a href=\"http://en.wikipedia.org/wiki/Depth_of_field\">Source</a></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"dof2.jpg\" />\n",
    "    <center><figcaption>Fig.8 (b): change of aperture <a href=\"http://rubbingpixels.com/depth-field-used-photography/\">Source</a></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field of View (zooming)\n",
    "\n",
    "How wide of a view do we have. There are two types of lens that can change their field of view:\n",
    "\n",
    "1. changing focal lenght while staying in constant focus\n",
    "2. changing focal length but must refocus (variable focal length lenses)\n",
    "\n",
    "When the focal length is high, the angular deflection moves the pixels drastically and thus any shake in the camera will shake the image greatly. So the more the focal length, the more we need to stabilize the camera. \n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"fov2.jpg\" />\n",
    "  <center><figcaption>Fig.9 (a): change in field of view as we change focal length <a href=\"http://www.capturedbyone.com/cbo-blog/know-your-focal-length-and-lens-field-of-view\">Source</a></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"fov.jpg\" />\n",
    "  <center><figcaption>Fig.9 (b): example change in field of view as we change focal length <a href=\"https://www.bhphotovideo.com/explora/photography/buying-guide/prime-lens-101\">Source</a></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "###  FOV depends on Focal Length\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"fov3.png\" />\n",
    "  <center><figcaption>Fig.9 (c): Calculating FOV </figcaption></center>\n",
    "</figure>\n",
    "\n",
    "The field of view can be calculated by calculating the angle $\\phi$ depected in Figure 9(c). \n",
    "\n",
    "$$\\phi = tan^-1(\\frac{d/2}{f})$$\n",
    "\n",
    "$d$: the retina or sensor size\n",
    "\n",
    "<font color=\"green\">Larger Focul Length $\\implies$ Smaller FOV <br/></font>\n",
    "<font color=\"green\">Bigger the imaging surface $\\implies$ Bigger FOV</font>\n",
    "\n",
    "<br />\n",
    "\n",
    "<font color=\"blue\">**Quize**</font>\n",
    "\n",
    "<figure>\n",
    "  <img src=\"fov_quiz.png\" />\n",
    "  <center><figcaption>Fig.9(d): Field of view quiz</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{1}{f} =  \\frac{1}{||z||} + \\frac{1}{||z'||}$$\n",
    "$$\\implies \\frac{1}{f} =  \\frac{z' + z}{z'z}$$\n",
    "$$\\implies fz' + fz = zz'$$\n",
    "$$\\implies fz' = zz' - fz$$\n",
    "$$\\implies fz' = z(z' - f)$$\n",
    "$$\\implies z = \\frac{z'f}{z'-f} \\,\\,(1)$$  \n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "$$\\frac{d/2}{z'} =  \\frac{w/2}{z}$$\n",
    "$$\\implies z =  \\frac{w/d}{z'} \\,\\,(2)$$ \n",
    "\n",
    "<br />\n",
    "\n",
    "<center>from 1 & 2</center>\n",
    "\n",
    "\n",
    "$$\\implies \\frac{z'f}{z'-f} =  \\frac{w/d}{z'}$$\n",
    "$$\\implies w(z'-f) =  df$$\n",
    "$$\\implies z' -f  =  \\frac{df}{w}$$\n",
    "$$\\implies z'  =  \\frac{df}{w} + f$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 52.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "w = 0.7*1000 #to mm\n",
    "f = 50\n",
    "d = 35\n",
    "zp = d*f/w + f ## df/w + f\n",
    "z = zp*w/d ## z = z'w/d\n",
    "\n",
    "print(z/1000,zp) # to m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zooming and Moving are not the same\n",
    "\n",
    "In Figure 10(a), the image on the left image were taken with a large FOV, and small $f$ while the camera is close to the car. The image on the right, on the other hand, is taken with small FOV, and large $f$ while the camera is far from the car. You can notice that the shape is different. The left image has what is called *Perspctive Distortion*. \n",
    "\n",
    "Figure 10(b) gives another example of *Perspctive Distortion* as we minimize $f$ and move closer to the face\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"zoomingvsmoving.png\" />\n",
    "  <center><figcaption>Fig.10 (a): zooming vs moving </figcaption></center>\n",
    "</figure>\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"zoomingvsmoving2.png\" />\n",
    "  <center><figcaption>Fig.10 (b): zooming vs moving </figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dolly Zoom\n",
    "\n",
    "When the camera move closer and closer to an object while widening the lense at the same time, the object in the middle will have the same size, and to maintain its stationary point. However, this will create an illusionary scene where the stuff on the outside will grow. \n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"zvmi3.gif\" />\n",
    "  <center><figcaption>Fig.11: Dolly Zoom</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenses Are Not Perfect\n",
    "\n",
    "There are many problems that might arise from lenses, photographers, or the scene.\n",
    "\n",
    "### Geometric Distortion\n",
    "\n",
    "You can correct geometric distortion in post-imaging tools like photoshop if you know the focal length of your camera Figure 12(b)\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"gmd.png\" />\n",
    "  <center><figcaption>Fig.12 (a): Geometric Distortion</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"gmdc.png\" />\n",
    "  <center><figcaption>Fig.12 (b): Correction of Radial Distortion</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Chromatic Aberration\n",
    "\n",
    "This problem happens when rays of different wavelength focus in different planes. The problem is how to get all lights from a certain point to land on same point on the image. Notice the red line in the bigger picture in Figure 12(d)\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"chrabb.png\" />\n",
    "  <center><figcaption>Fig.12 (c): Chromatic Aberration</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"chrabb2.png\" />\n",
    "  <center><figcaption>Fig.12 (d): Chromatic Aberration Example</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Vignetting\n",
    "\n",
    "With some camera settings, not all rays that are hitting in the middle of the image are being caught at the corners. \n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "<img src=\"vignetting2.png\" />\n",
    "  <center><figcaption>Fig.12 (e): Vignetting <a href=\"https://photographylife.com/what-is-vignetting\">Source</a></figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "<img src=\"vignetting3.jpg\" />\n",
    "  <center><figcaption>Fig.12 (f): Example of Vignetting <a href=\"https://forums.bohemia.net/forums/topic/146786-vignetting/\">Source</a></figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lense Systems\n",
    "\n",
    "Advanced cameras have multiple lenses. The camera in Figure 13 has 15 lenses that change according to the need.  \n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"lenses_system.png\" />\n",
    "  <center><figcaption>Fig.13: Example of advanced camera lenses</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  3A - L2 Perspective Imaging\n",
    "# ====================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Systems\n",
    "\n",
    "- Using the pinhole model as an approximation\n",
    "    - Put the optical center (Center of Projection) at the origin\n",
    "    - Standard (x,y) Coordinate System\n",
    "    - Put the image plane (Projection Plane) in front of the COP (for math convenient)\n",
    "    - The cameral looks down the negative z axis\n",
    "    \n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"coordinate_system.png\" />\n",
    "  <center><figcaption>Fig.14: depects the coordinate system for modeling projection</figcaption></center>\n",
    "</figure>\n",
    "    \n",
    "\n",
    "<br />\n",
    "\n",
    "### Projection Equations\n",
    "\n",
    "- Compute intersection with Perspective Projection of ray from (x,y,z) to COP\n",
    "- Derived using similar triangles\n",
    "\n",
    "$$(X,Y,Z) -> (-d\\frac{X}{Z},-d\\frac{Y}{Z},-d)$$\n",
    "\n",
    "\n",
    "So, we can get the projection by throwing out the last coordinate:\n",
    "\n",
    "$$(x', y') = (-d\\frac{X}{Z},-d\\frac{Y}{Z})$$\n",
    "\n",
    "<font color=\"green\">**When dividing by Z, distant objects are smaller</font>\n",
    "\n",
    "<br />\n",
    "\n",
    "<font color=\"blue\">**Quize**</font>\n",
    "\n",
    "When objects are very far away, the real X and real Z can be huge. If I move the camera (the origin), those numbers hardly change. This explains:\n",
    "\n",
    "a) Why the moon follows you<br />\n",
    "b) Why the North Star is always North<br />\n",
    "c) Why you can tell time from the Sun regardless of where you are?<br />\n",
    "<font color=\"green\">d) All of the above</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneous Coordinates\n",
    "\n",
    "\n",
    "Is this a linear transformation?<br />\n",
    "No- division by the (not constant) Z is non-linear<br />\n",
    "\n",
    "<font color=\"green\">Trick: add one more coordinate:</font>\n",
    "\n",
    "Homogeneous image (2D) coordinates$\\,\\,\\,(x,y)\\,\\,\\, \\Rightarrow \\begin{bmatrix} x \\\\ y \\\\ 1\\end{bmatrix} $<br /><br />\n",
    "Homogeneous scene (3D) coordinates$\\,\\,\\,(x,y,z) \\Rightarrow \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} $\n",
    "\n",
    "\n",
    "#### Converting from homogeneous coordinates: \n",
    "$$\\begin{bmatrix} x \\\\ y \\\\ w\\end{bmatrix} \\,\\,\\, \\Rightarrow \\,\\,\\,(x/w,y/w)$$\n",
    "<br />\n",
    "<br />\n",
    "$$\\begin{bmatrix} x \\\\ y \\\\ z \\\\ w\\end{bmatrix} \\,\\,\\, \\Rightarrow \\,\\,\\,(x/w,y/w,z/w)$$\n",
    "\n",
    "\n",
    "<font color=\"green\">**This makes homogenous coordinates invariant under scale</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Projection\n",
    "projetion is a matrix multiply using homogeneous coordinates:\n",
    "\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{f} & 0  \\end{bmatrix}\\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\\\ \\frac{z}{f}\\end{bmatrix}  \\,\\,\\, \\Rightarrow \\,\\,\\,(f\\frac{x}{z},f\\frac{y}{z})$$\n",
    "\n",
    "\n",
    "$$\\Rightarrow (u,v)$$\n",
    "\n",
    "$f$: is the focal length, the distance from the center of projection to the image plane\n",
    "\n",
    "<font color=\"blue\">How does scaling the projection matrix change the transformation?</font>\n",
    "\n",
    "$$\\begin{bmatrix} f & 0 & 0 & 0 \\\\ 0 & f & 0 & 0 \\\\ 0 & 0 & 1 & 0  \\end{bmatrix}\\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix} fx \\\\ fy \\\\ z \\end{bmatrix}  \\,\\,\\, \\Rightarrow \\,\\,\\,(f\\frac{x}{z},f\\frac{y}{f})$$\n",
    "\n",
    "<font color=\"green\">**So invariant under scale</font>\n",
    "\n",
    "<font color=\"blue\">**Quize**</font>\n",
    "\n",
    "Given Point p in 3-space[x y z] and focal length f, write a function that returns the location of the projected point on 2D image plane [u v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def project(p,f):\n",
    "    A = np.array([[1,0,0,0],[0,1,0,0],[0,0,1/f,0]])\n",
    "    p = np.append(p,1)\n",
    "    mul = np.matmul(A,p.T)\n",
    "    return (mul[0]/mul[2],mul[1]/mul[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200.0, 100.0)\n",
      "(100.0, 50.0)\n"
     ]
    }
   ],
   "source": [
    "p1 = np.array([200,100,50])\n",
    "p2 = np.array([200,100,100])\n",
    "f = 50\n",
    "print(project(p1,f))\n",
    "print(project(p2,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric properties of projection\n",
    "\n",
    "- Points go to points\n",
    "- Lines go to lines\n",
    "- Polygons go to polygons\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"proj_gpr.png\" />\n",
    "  <center><figcaption>Fig.15: properties of projection</figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Lines in the World Meet in the Image (Vanishing) point\n",
    "\n",
    "\n",
    "Line in 3-space\n",
    "\n",
    "$$x(t) = x_0 + at$$\n",
    "$$y(t) = y_0 + bt$$\n",
    "$$z(t) = z_0 + ct$$\n",
    "\n",
    "$x_0, y_0,z_0$:  is starting point <br/>\n",
    "$at,bt,zt$:  moving on vector <br/>\n",
    "\n",
    "\n",
    "#### Perspective projection of the line\n",
    "\n",
    "$$x'(t) = \\frac{fx}{z} =  \\frac{f(x_{0} + at)}{z_0 + ct} $$\n",
    "<br />\n",
    "$$y'(t) = \\frac{fy}{z} =  \\frac{f(y_{0} + bt)}{z_0 + ct}$$\n",
    "\n",
    "<br />\n",
    "In the limit as $t \\rightarrow \\pm$ we have (for  $c \\neq 0$) :\n",
    "\n",
    "$$x'(t) \\rightarrow \\frac{fa}{c}, \\,\\,\\,\\, y'(t) \\rightarrow \\frac{fb}{c}$$\n",
    "\n",
    "regardless of their starting point (that is $x_0\\,\\, and\\,\\, y_0$)\n",
    "\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"vanishing_point.png\" />\n",
    "  <center><figcaption>Fig.16(a): Vanishing Point</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"vanishing_point2.png\" />\n",
    "  <center><figcaption>Fig.16(b): Example of Vanishing Point</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing Points\n",
    "\n",
    "- Each set of parallel lines (=direction) meets at a different point.\n",
    "    - The line is called the horizon for that plane\n",
    "    \n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"parallel_lines.png\" />\n",
    "  <center><figcaption>Fig.17 (a): set of parallel lines</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "#### 3-point perspective\n",
    "\n",
    "Different directions correspond to different vanishing points\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"threepoint_pers.png\" />\n",
    "  <center><figcaption>Fig.17(b): 3-point perspective</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"vanishing_point3.png\" />\n",
    "  <center><figcaption>Fig.17(c): example of vanishing point</figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Vision (Muller-Lyer illusion)\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"hv_pl.png\" />\n",
    "  <center><figcaption>Fig.18(a): illusion to human vision</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"hv_pl2.png\" />\n",
    "  <center><figcaption>Fig.18(b): illusion to human vision</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Quize**</font>\n",
    "\n",
    "What determines at what point in the image parallel lines intersect?\n",
    "\n",
    "\n",
    "a) The direction the lines have in the world<br />\n",
    "b) Whether the world lines are on the ground plane<br />\n",
    "c) The orientation of the camera<br />\n",
    "<font color=\"green\">d) (a) and (c)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other models\n",
    "\n",
    "#### Orthograpphic Projection\n",
    "\n",
    "Special case of perspective projection\n",
    "- Distance from the COP to the image plane is infinite\n",
    "- Also called 'parallel projection':\n",
    "(x,y,z) -> (x,y)\n",
    "- The projection matrix is:\n",
    "\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1  \\end{bmatrix}\\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}  \\,\\,\\, \\Rightarrow \\,\\,\\,(x,y)$$\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"orth_proj.png\" />\n",
    "  <center><figcaption>Fig.19(a): Orthograpphic Projection</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "#### Week Perspective\n",
    "\n",
    "- Perspective effects, but not over the scale of individual objects\n",
    "\n",
    "$$(x,y,z) \\,\\,\\,\\, \\rightarrow (\\frac{fx}{z_0},\\frac{fy}{z_0})$$\n",
    "\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & \\frac{1}{s}  \\end{bmatrix}\\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\\\ \\frac{1}{s}  \\end{bmatrix}  \\,\\,\\, \\Rightarrow \\,\\,\\,(sx,sy)$$\n",
    "\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"week_per.png\" />\n",
    "  <center><figcaption>Fig.19(a): Week Perspective</figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\frac{}{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{bmatrix} 1 & 2 & -1\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a href=\"\">Source</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<font color=\"blue\"></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "<figure>\n",
    "  <img src=\"hv_pl.png\" />\n",
    "  <center><figcaption>Fig.</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
