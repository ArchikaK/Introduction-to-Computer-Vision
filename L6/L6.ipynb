{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# 6A - L1 Introduction to Motion\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Motion\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L61.gif\" />\n",
    "    <center><figcaption>Fig.1(a): example of gif</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "## Video \n",
    "\n",
    "A video is a sequene of frames captured over time - usually quickly\n",
    "\n",
    "- Now our image data is a function of smape (x,y) and time (t)\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L62.png\" />\n",
    "    <center><figcaption>Fig.1(b)</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Applications: Bideo segmentation\n",
    "\n",
    "**Background subtraction**\n",
    "\n",
    "- A static camera is observing a scene\n",
    "- Goal: seperate the static background from the moving foreground\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L63.png\" />\n",
    "    <center><figcaption>Fig.2(a)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Shot boundary detection**\n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L64.png\" />\n",
    "    <center><figcaption>Fig.2(b)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Motion segmentation**\n",
    "- Segment the video into multiple coherently moving objects\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L65.png\" />\n",
    "    <center><figcaption>Fig.2(c)</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion and perceptual organization\n",
    "\n",
    "- Gestalt psychology (Wertheimer, 1880-1943)\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L66.png\" />\n",
    "    <center><figcaption>Fig.3(a)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "- Sometimes, motion is the only cue\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L67.png\" width=\"200px\" />\n",
    "    <img src=\"imgs/L68.png\" width=\"200px\"/>\n",
    "    <img src=\"imgs/L69.gif\" width=\"200px\"/>\n",
    "    <center><figcaption>Fig.3(b)</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impverished Motion\n",
    "\n",
    "- Even \"impoverished\" motion data can evoke a strong percept\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L610.png\" width=\"200px\"/>\n",
    "    <img src=\"imgs/L611.gif\" width=\"200px\"/>\n",
    "    <center><figcaption>Fig.4: notice the center point is not moving. Focus on it and you see how weird it is. Try to take it out of your head after that !!!</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "Examples of Impoverished Motion\n",
    "\n",
    "Video: <a href=\"https://www.youtube.com/watch?v=1F5ICP9SYLU\">2-Dimensional Motion Perception</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Applications of Motion Analysis\n",
    "\n",
    "### Mosaicing\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L612.png\" width=\"400px\" />\n",
    "    <img src=\"imgs/L613.png\" width=\"400px\"/>\n",
    "    <center><figcaption>Fig.5</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "- **Segmentation of objects in space or time**\n",
    "- **Estimating 3D structure**\n",
    "- **Learning dynamical models - how things move**\n",
    "- **Recognizing events and activities**\n",
    "- **Improving video quality (motion stabilization)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Estimation Techniques\n",
    "\n",
    "**Featured-based methods**\n",
    "\n",
    "- Extract visual features (corners, textured areas) and track them over multiple frames\n",
    "- Sparse motion fields, but more robust tracking\n",
    "- Suitable when image motion is large (10s of pixels)\n",
    "\n",
    "**Direct, dense methods**\n",
    "\n",
    "- Directly recover image motion at each pixel from spatio-temporal image brightness variations\n",
    "- Dense motion fields, but sensitive to appearance variations\n",
    "- Suitable for video and whn image motion is small\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# 6B - L1 Dense flow: Brightness constraints\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion estimation: Optical flow\n",
    "\n",
    "Optic flow is the **apparent** motion of objects or surfaces\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L614.png\" width=\"400px\" />\n",
    "    <center><figcaption>Fig.6</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition: Optical Flow\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L615.png\" width=\"400px\" />\n",
    "    <center><figcaption>Fig.7</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "How to estimate pixel motion from image $I(x,y,t)$ to $I(x,y,t+1)$?\n",
    "\n",
    "\n",
    "-> Solve pixel correspondence problem <br/>\n",
    "- Given a pixel in $I(x,y,t)$, look for *nearby* pixels of the *same color *in $I(x,y,t+1)$\n",
    "\n",
    "**This is the optic flow problem**\n",
    "\n",
    "\n",
    "- Color constancy: a point in $I(x,y,t)$ looks the same in $I(x',t',t+1)$ \n",
    "    - For grayscale images, this is the ***brightness constancy***\n",
    "- Small motion: points do not move very far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical flow constraints (grayscale images)\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L616.png\" width=\"400px\" />\n",
    "    <center><figcaption>Fig.8</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "1) Brightness constancy constraint (equation)\n",
    "$$I(x,y,t) = I(x+u,y+v,t+1)$$\n",
    "$$0 = I(x+u,y+v,t+1)-I(x,y,t)$$\n",
    "\n",
    "2) Small motion: (u and v are less than 1 pixel, or smooth)\n",
    "\n",
    "Taylor series expansion of $I$:\n",
    "\n",
    "$$I(x+u,y+v) = I(x,y) + \\frac{\\partial I}{\\partial x}u + \\frac{\\partial I}{\\partial y}v + [higher\\, order\\, terms]$$\n",
    "$$I(x+u,y+v) \\approx I(x,y) + \\frac{\\partial I}{\\partial x}u + \\frac{\\partial I}{\\partial y}v$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining these two equations:\n",
    "\n",
    "$$0 = I(x+u,y+v,t+1)-I(x,y,t)$$\n",
    "$$0 \\approx I(x,y,t+1)-I_xu + I_yv - I(x,y,t)$$\n",
    "\n",
    "$I_x$: = $\\frac{\\partial I}{\\partial x}$ for $t$ or $t+1$\n",
    "\n",
    "$$0 \\approx [I(x,y,t+1)- I(x,y,t)]+I_xu + I_yv $$\n",
    "$$0 \\approx I_t+I_xu + I_yv $$\n",
    "\n",
    "<font color=\"blue\">**$$I_t + \\nabla I \\cdot <u,v>$$**</font>\n",
    "<font color=\"blue\">**$$\\implies 0 \\approx I_t + \\nabla I \\cdot <u,v>$$**</font>\n",
    "In the limit as $u$ and $v$ approaches zero, this becomes exact:\n",
    "<font color=\"blue\">**$$0 = I_t + \\nabla I \\cdot <u,v>$$**</font>\n",
    "\n",
    "Brightness constancy constraint equation\n",
    "\n",
    "\n",
    "<font color=\"blue\">$$I_xu + I_yv + I_t = 0$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Component of Flow\n",
    "\n",
    "Q: How many unknowns and equations per pixel?\n",
    "\n",
    "<pre><font color=\"red\">2 unknown(u,v) but 1 equaton</font></pre>\n",
    "\n",
    "Intuitively, what does this constraint mean?\n",
    "\n",
    "- The component of the flow in the gradient direction is determined\n",
    "- The component of the flow parallel to an edge is unknown\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L617.png\" width=\"400px\" />\n",
    "    <center><figcaption>Fig.9</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture problem\n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "    <img src=\"imgs/L618.gif\" width=\"400px\" />\n",
    "    <img src=\"imgs/L619.gif\" width=\"400px\" />\n",
    "    <center><figcaption>Fig.10 (a)</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "## Gradient component of flow\n",
    "\n",
    "Some falks say: \"This explains the Barber Pole illusion\"\n",
    "\n",
    "http://www.sandlotscience.com/Ambiguous/Barberpole_Illusion.htm <br/>\n",
    "http://www.liv.ac.uk/~marcob/Trieste/barberpole.html\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/L620.gif\" width=\"400px\" />\n",
    "    <center><figcaption>Fig.10(b): This animation simulates a set of black and white stripes moving rightwards behind a black mask with four holes. Look at the leftmost hole and compare it with the bottom center hole. These are instances of the \"barberpole\" effect (Wallach,1935/1996). The perceived direction of motion is the predominant direction of the stripe terminators, following the longest side of the hole. In the rightmost hole, the sides are first horizontal, then vertical, then turn horizontal again. Accordingly, the stripes appear to go right, turn downwards, and then turn right again. In a circular hole, the terminators do not have a predominant direction and the stripes appear to move perpendicularly to their orientation. The barberpole effect suggests that contour terminators play an important role in determining the perceived motion of an object</figcaption></center>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additinal Flow Constraints Quize\n",
    "\n",
    "\n",
    "What additional constraints you can use: <br/>\n",
    "\n",
    "- <font color=\"green\">Nearby pixels move together</font>\n",
    "- <font color=\"green\">Motion must be consistent over the entire image</font>\n",
    "- <font color=\"green\">Only consider distinct regions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Optical Flow (Horn and Schunck - long ago)\n",
    "\n",
    "- Formulate Error in Optical Flow Constraint:\n",
    "\n",
    "$$e_c = \\int \\int_{image} (I_xu+I_yv+I_t)^2dxdy$$\n",
    "\n",
    "- We need additional constraints (pardon the integrals)\n",
    "\n",
    "- Smoothness constraint: motion field tends to vary smoothly over the image\n",
    "\n",
    "$$e_s= \\int \\int_{image} (u_x^2 + u_y^2)+(v_x^2 + v_y^2)dxdy$$\n",
    "\n",
    "- Penalized for changes in $u$ and $v$ over the image\n",
    "\n",
    "Given both terms, find $(u,v)$ at each image point that minimizes:\n",
    "\n",
    "$$e=e_s+\\lambda e_c$$\n",
    "\n",
    "$\\lambda$: weighting factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">I kind of looked like Megan as I was typing the notes for this lesson (recording with no idea whatsoever of what he is talking about). Let's hope the king charges me back with stormlight smartness as Barcelona faces Madrid in the copa del rey tomorrow</font>\n",
    "<img src=\"imgs/messi.png\" align=\"middle\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
