{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "#  7A - L1 Introduction to tracking\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of tracking\n",
    "\n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L71.gif\" width=300/>\n",
    "  <img src=\"imgs/L72.gif\" width=300/>\n",
    "  <center><figcaption>Fig.1(a) Old example</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "------------------\n",
    "\n",
    "\n",
    "<br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L73.gif\" width=300/>\n",
    "  <img src=\"imgs/L74.gif\" width=300/>\n",
    "  <center><figcaption>Fig.1(b) Newer examples</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Challenge\n",
    "\n",
    "1. Many places it's hard to compute opticl flow.\n",
    "2. There can be large displacements since could be moving rapidly\n",
    "    probably need to take dynamics into account\n",
    "3. Errors would compound - or drift\n",
    "4. Occlusions, disocclusions \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shi-Tomasi feature tracker\n",
    "\n",
    "\"Only compute motion where you should?\n",
    "\n",
    "Find good features using eigenvalues of second-moment matrix - you've seen the now twice!\n",
    "\n",
    "- Key idea: \"good\" features to track are the ones that can be tracked reliably\n",
    "\n",
    "\n",
    "1. From frame to frame, track with Lcas-Kanade and a pute translation model\n",
    "    - More robust for small displacements, can be estimated from smaller neighborhoods\n",
    "    \n",
    "2. Check consistency of tracks by affine registration to the first (or earlier) observed instance of the feature\n",
    "    - Affine model is more accurate for larger displacements\n",
    "    - Comparing to the first or early frame helps to minimize drift\n",
    "    \n",
    "  <br />\n",
    "<figure>\n",
    "  <img src=\"imgs/L75.png\" width=300/>\n",
    "  <center><figcaption>Fig.2 J.Shi and C.Tomasi. *Good Features to Track* CVPR 1994</figcaption></center>\n",
    "</figure>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking with Dynamics\n",
    "\n",
    "Key idea: Given a model of expected motion, predict where objects will occur in the next frame, even before seeing the image\n",
    " - Restrict search for object\n",
    " - Improved estimates since measurement noise is reduced by trajectory smoothness\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection vs Tracking\n",
    "\n",
    "The idea of using prediction is the difference between tracking and just detecting\n",
    "\n",
    "\n",
    "**Detection**: We *detect* the object *independently* in each frame\n",
    "\n",
    "  <br />\n",
    "<figure>\n",
    "<img src=\"imgs/L76.png\" width=500/>\n",
    "<center><figcaption>Fig.3(a): detection</figcaption></center>\n",
    "</figure> \n",
    "\n",
    "**Tracking**: We *predict* the new location of the object in the next frame using *estimated dynamics*. Then we *update* based upon measurements\n",
    "\n",
    "   <br />\n",
    "<figure>\n",
    "<img src=\"imgs/L77.png\" width=500/>\n",
    "<center><figcaption>Fig.3(b): tracking</figcaption></center>\n",
    "</figure> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking with dynamics \n",
    "\n",
    "Key idea: Given a model of expected motion, predict where objects will occur in the next frame, even before seeing the image\n",
    "\n",
    "**Goals**:\n",
    "\n",
    "- Do less work looking fro the object, restrict the search.\n",
    "- Get improved estimates since measurement noise is tempered by smoothness, dynamics priors\n",
    "\n",
    "**Assumption** continuous (modeled) motion patterns:\n",
    "- Objects do not disappear and reappear in different places in the scene  \n",
    "- Camera is not moving instantaniously to new viewpoint\n",
    "- Gradual change in pose between camera and scene\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
